---
title: "Survival Analysis Notes"
author: "Callum Arnold"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    toc: TRUE
    toc_float: TRUE
    number_sections: FALSE
    code_folding: hide
bibliography: survival-analysis.bib
link-citations: TRUE
---

# British Journal of Cancer Tutorial Series {#bjc-tutorials}

## Part 1 [@clarkSurvivalAnalysisPart2003] {#bjc-part1}

-   Often true time to event is not known (event hasn't occurred at end of
    follow up)

-   Survival data rarely normally distributed

    -   Typically many early events and few late ones

### Censoring

-   Survival times unknown for subset of study group

-   Censoring can happen in a number of ways

    -   Patient has not yet experienced outcome by end of study period

        -   **Right censoring**

    -   Patient is lost to follow up during study period

    -   Patient experiences different event making follow up impossible

-   Underestimates the true time to event

-   **Left censored**

    -   If we observe presence of a state/condition but don't know when it
        occurs

    -   We know the start point in this situation e.g. cancer reoccurence
        following surgery, as we know their surgical date

-   **Interval censored**

    -   Observe patients at intervals, and some may be lost to follow up between
        intervals, or time between intervals is large such that a person
        develops disease within the interval and precise onset can't be known

-   Most data is right censored, but methods exist for all types of censoring

### Illustrative Studies

-   Generally good to choose end-point that can't be mis-specified i.e.
    all-cause mortality vs mortality from specific condition

### Survival and Hazard

-   **Survival probability** (*survival function*) $S(t)$

    -   Probability an individual survives from the time origin to specified
        future time *t*

    -   Reflects the cumulative non-occurence

-   **Hazard** $h(t)$ or $\lambda(t)$

    -   Probability that an observed individual has an event at time *t*, i.e.,
        the instantaneous event rate for an individual who has survived to time
        *t*

    -   Hazard relates to the incident event rate

### Kaplan-Meier Survival Estimate

-   Non-parametric estimate from observed survival times

    -   Both censored and non-censored

-   *Assuming independent events*, multiply probabilities of surviving from one
    interval to the next to get the cumulative survival probability

$$
\begin{equation}
\begin{split}
S(t_j) &= S(t_{j-1}) \left(1 - \frac{d_j}{n_j}\right) \\
\text{where}: n_j &= \text{# people alive just before } t_j \\
d_j &= \text{# of events at } t_j
\end{split}
(\#eq:survivalfun)
\end{equation}
$$

-   For censoring, can think of as inputting $d_j = 0$ and reducing $n_j$ by 1
    (assuming one individual was censored at time $t_j$), resulting in
    $S(t_j) = S(t_{j-1})$

-   Often patients lost to follow-up/alive at end of study period, so CIs are
    wider than earlier making for difficulty in interpretation

    -   May want to curtail x-axis for this reason

-   For low incidence events, plotting cumulative incidence instead of
    cumulative survival can be useful

### Hazard and Cumulative Hazard

-   Relationship between survival and hazard given by equation

$$
h(t) = - \frac{d}{dt}[\log S(t)] (\#eq:hazard)
$$

-   No simple way to estimate $h(t)$

    -   Instead need to estimate the **cumulative hazard** $H(t)$

$$
\begin{equation}
\begin{split}
H(t) &= \int h(t) \, dt \\
&= - \log [S(t)]
\end{split}
(\#eq:cum-hazard)
\end{equation}
$$

-   Cumulative hazard can be though of as the number of events to be expected
    for each individual by time $t$ if the event was a repeatable process

-   Cumulative hazard used to estimate $h(t)$, and as a diagnostic tool of model
    validity

-   **Nelson-Aalen estimator** is a simple non-parametric estimate of $H(t)$

-   Can also estimate hazard by assuming survival times follow a specific
    distribution (parametric estimation), for example:

    -   Constant hazard (e.g. healthy individuals) = exponential distribution

    -   Strictly increasing (e.g. leukaemia patients)/decreasing (e.g. patients
        recovery from surgery) hazard = Weibull

    -   Increasing then decreasing log-Normal (e.g. TB patients)

### Non-parametric Tests Comparing Survival

-   Logrank test most widely used to compare curves

    -   Calculates at each event time, for each group, expected number of events
        since previous if no difference between groups, summed over all event
        times, giving total expected number of events for each group

    -   $\chi^2$ test for observed vs expected in each group with $g-1$ degrees
        of freedom where $g$ is the number of groups (survival curves)

    -   When only 2 groups, is $H_0$ that the **hazard ratio** = 1

        -   Usually best to estimate with regression e.g., Cox regression, but
            can calculate with observations/estimated

    -   More robust than comparing medians, but lack of effect size is a
        limitation

-   If natural order, can do a test for trend

    -   Compare to $\chi^2$ distribution with 1 df

### Some Key Requirements for the Analysis of Survival Data

-   Standard methods require **noninformative censoring**

    -   Censored individuals shouldn't differ in their chance of experiencing an
        event e.g. informative when patients withdraw from trial due worsening
        clinical condition

-   Must have sufficient follow up time to capture enough events

    -   Sufficient power for test

-   Good estimate of follow up time is the **reverse KM estimator**

    -   Censoring is the event of interest

-   Unequal of follow up between groups can bias analysis

-   Need to take into account **cohort effects**

    -   Assumption of homogeneity of treatment/other factors during study period
        may not hold e.g. long study period of cancer patients and detection
        methods improve so cases detected earlier in disease progression (not
        accounted for by groups)

-   Consistency in methods between multiple participating centres

## Part 2 [@bradburnSurvivalAnalysisPart2003]

### The Need for Multivariate Statistical Modelling

-   Logrank test only provides p-value, not an estimate of effect size

    -   We need a statistical model to do this, and account for covariates

-   Two main approaches

    -   Proportional hazards e.g. semi-parametric Cox model and fully parametric
        approaches

    -   Accelerated failure time models

### The Cox ("Semi-parametric") Proportional Hazards Model

-   Regression model that describes the relation between event incidence
    (expressed by hazard function) and covariates

$$
h(t) = h_0(t) \times \exp\{b_1 x_1 + b_2 x_2 + ... + b_p x_p \} (\#eq:cox-model)
$$

-   Baseline hazard ($h_0(t)$) estimated non-parametrically, so survival times
    are not assumed to follow a distribution

-   Effectively a linear regression of the logarithm of the hazard on the
    covariates $x_i$ with coefficients $b_i$

    -   Covariates act manipulatively on hazard

-   Key assumption

    -   The hazard in any group is a **constant multiple** of the hazard in the
        other groups i.e. **proportional hazards,** therefore the hazard curves
        cannot cross

        -   Often appropriate assumption for survival data, but must be
            confirmed

-   $\exp(b_i)$ are the **hazard ratios**

    -   HR > 1 means increased hazard of the event i.e. decreased survival time

### Parametric PH Models

-   Same interpretation of regression results as Cox model, but assumes survival
    times and hazards follow a distribution

-   Assumes proportional hazards

-   Most common distributional assumptions

    -   Exponential

    -   Weibull

    -   Gompertz

### Comparison of the Two PH Approaches

-   Sometimes difficult to identify appropriate distribution of survival times

-   Parametric model more informative than Cox model when have correct
    distribution

    -   Straightforward to derive hazard function and obtain predicted survival
        times

    -   Slightly more *efficient* i.e. smaller standard errors

-   For either to be valid:

    -   Covariate effect needs to be at least approximately constant throughout
        study period

    -   Proportionality assumption holds

### Interpreting the PH Model: Beyond the Hazard Ratio

-   Useful to estimate predicted survival proportion at a given time point for a
    group

$$
S(t) = S_0(t) ^{\exp\{b_1 x_1 + b_2 x_2 + ... + b_p x_p \}} (\#eq:surv-prop)
$$

### Accelerated Failure Time Models

$$
\begin{equation}
\begin{split}
S(t) &= S_0 (\varphi t) \\
&= S_0 \left(\exp\{b_1 x_1 + b_2 x_2 + ... + b_p x_p \} t \right)
\end{split}
(\#eq:aft-model)
\end{equation}
$$

-   $S_0(t)$ is the baseline survivor function and $\varphi$ is the
    **accelerator** **factor**
-   The effect of the covariate is to stretch or shrink the survival curve along
    the time axis by a constant relative amount, $\varphi$
-   The AFT model is commonly rewritten as being log-linear with respect to time

$$
\begin{equation}
\begin{split}
\log(T) &= b_1 x_1 + b_2 x_2 + ... + b_p x_p + \varepsilon \\
\text{where}: \varepsilon &= \text{residual variability in survival times}
\end{split}
(\#eq:loglin-aft-model)
\end{equation}
$$

-   Survival times multiplied by a constant effect

-   $\exp(b_i)$ are **time ratios**

    -   \>1 for a covariate = increases the time to event

-   When survival times follow Weibull, AFT and PH models are the same

    -   Interpretation of effect sizes differs - time vs hazard ratios

-   Normal distributional assumptions in AFT models:

    -   Log-Normal

    -   Log-Logistic

    -   Generalised Gamma

    -   Weibull

-   Can implement semi-parametric AFT

    -   Baseline survivor function is estimated non-parametrically

-   Assumptions:

    -   Appropriate distribution

    -   Covariate effects assumed to be constant and multiplicative on the
        timescale i.e. impacts on survival by a constant factor

### Which Model Should We Use: PH or AFT?

-   Initially, which fits the data better?

-   Assuming both fit similarly:

    -   Norm within field i.e. ease of comparability if HRs common vs TRs

    -   Parametric approach of AFT offers more in the way of prediction

    -   TRs arguably more interpretable than HRs

### Other Approaches

-   More straighforward to incorporate covariates using stratified survival
    analysis

    -   Use logrank or similar method to compare within strata, and combined for
        overall comparison adjusted for the strata e.g. stage of disease

    -   No distributional assumptions made and simple interpretation

    -   Only applicable with categorical variables and for few covariates

    -   Does not quantify effect, and only p-value for variable of primary
        interest

    -   Good for exploratory analysis

#### Aalen's additive hazard model

-   Assumes covariates impact additively on baseline hazard, but effects are not
    constrained to be constant

    -   Impact can vary over time

$$
h(t) = h_0(t) + b_1(t) x_1 + b_2(t) x_2 + ... + b_p(t) x_p (\#eq:aalen-additive)
$$

-   Not simple to estimate baseline hazard non-parametrically, so need to use
    cumulative baseline, as well as estimating cumulative additional hazards as
    the regression coefficients

$$
B_i(t) = \int_0^t b_i(u) du (\#eq:cum-add-hazard)
$$

-   Plotting $B_i(t)$ is sometimes called Aalen plots, and the slope can be used
    to infer the relative increase in hazard at time $t$, but not the absolute
    increase ($b_i(t)$)

    -   Can be used to informally assess PH assumption

-   Difficult to interpret and $B_i(t)$ coefficients can change rapidly over
    time so no single effect size estimate

## Part 3 [@bradburnSurvivalAnalysisPart2003a]

# References {#refs}
